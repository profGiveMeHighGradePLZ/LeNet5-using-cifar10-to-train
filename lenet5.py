# -*- coding: utf-8 -*-
"""LeNet5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1szqeBmn9bMuHdJXmIOzHJe8bTFFR4o40

## 初始化数据库
"""

import torch
import torchvision
import torchvision.transforms as transforms
import torch.utils.data

"""dataset
dataloader
"""

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))
   #`normalize`函数通常用于将数据标准化为特定的范围或分布，
    #例如将像素值标准化到0到1之间或使用Z-score标准化。这有助于训练模型更快地收敛并提高模型的稳定性。
])

trainset = torchvision.datasets.CIFAR10(root = './data',train = True,download = True,transform = transform)
testset = torchvision.datasets.CIFAR10(root = './data',train = False,download = True,transform = transform)

trainloader = torch.utils.data.DataLoader(trainset,batch_size = 4,shuffle = True,num_workers = 0)
testloader = torch.utils.data.DataLoader(trainset,batch_size = 4,shuffle = False,num_workers = 0)

classes = ('airplane','automoblie','bird','cat','deer','dog','frog','horse','ship','truck')

import matplotlib.pyplot as plt
import numpy as np

def imshow(img):
  img = img/2 + 0.5
  npimg = img.numpy()
  plt.imshow(np.transpose(npimg,(1,2,0)))
  plt.show()

dataiter = iter(trainloader)
images,labels = next(dataiter)

imshow(torchvision.utils.make_grid(images))

print(labels)
print(labels[0],classes[labels[0]])
print(' '.join(classes[labels[j]] for j in range(4)))

"""# 定义神经积卷网络"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
      super(Net,self).__init__()
      self.conv1 = nn.Conv2d(3,6,5)
      self.conv2 = nn.Conv2d(6,16,5)
      self.fc1 = nn.Linear(16*5*5,120)
      self.fc2 = nn.Linear(120,84)
      self.fc3 = nn.Linear(84,10)

    def forward(self,x):
      x = self.conv1(x)
      x = F.relu(x)
      x = F.max_pool2d(x,2)
      x = F.max_pool2d(F.relu(self.conv2(x)),2)
      x = x.view(-1,x.size()[1:].numel())
      x = F.relu(self.fc1(x))
      x = F.relu(self.fc2(x))
      x = self.fc3(x)
      return x

net = Net()
print(net)

"""# 定义损失函数"""

criterion = nn.CrossEntropyLoss()

import torch.optim as optim
optimizer = optim.SGD(net.parameters(),lr = 0.001,momentum = 0.9)

"""# 训练"""

for epoch in range(3):

    running_loss = 0.0
    for i,data in enumerate(trainloader,0):
        inputs,labels = data

        optimizer.zero_grad()

        outputs = net(inputs)
        loss = criterion(outputs,labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        if i % 2000 == 1999:
          print('[%d,%5d] loss:%.3f' % (epoch+1,i+1,running_loss/2000))
          running_loss = 0.0

print('Finish')

PATH='./cifar_net.pth'
torch.save(net.state_dict(),PATH)

"""# 测试效果"""

dataiter = iter(testloader)
images,labels = next(dataiter)
imshow(torchvision.utils.make_grid(images))
print('GroundTruth:',' '.join('%5s'% classes[labels[j]] for j in range(4)))

net = Net()
PATH='./cifar_net.pth'
net.load_state_dict(torch.load(PATH))

outputs = net(images)

_,predicted = torch.max(outputs,1)

correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images,labels = data
        outputs = net(images)
        _,predicted = torch.max(outputs,1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

correctGailv = 100*(correct/total)
print(correctGailv)